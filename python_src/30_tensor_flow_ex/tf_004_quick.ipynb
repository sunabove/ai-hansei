{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스 : 빠르게 훑어보기\n",
    "https://www.tensorflow.org/guide/keras/overview?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential 모델 만들기\n",
    "간단한 완전 연결(fully-connected) 네트워크, 다층 퍼셉트론를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# 64개의 유닛을 가진 완전 연결 층을 모델에 추가합니다:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# 또 하나를 추가합니다:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# 10개의 출력 유닛을 가진 소프트맥스 층을 추가합니다:\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "층 설정 <br/>\n",
    "<p><a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers?hl=ko\"><code>tf.keras.layers</code></a> 아래의 클래스들은 일부 생성자 매개변수를 공통으로 가지고 있습니다:</p>\n",
    "<ul>\n",
    "<li><code>activation</code>: 층의 활성화 함수를 설정합니다. 이 매개변수에는 기본으로 제공되는 함수의 이름을 쓰거나\n",
    "호출 가능한 객체를 지정할 수 있습니다. 기본값은 활성화 함수를 적용하지 않는 것입니다.</li>\n",
    "<li><code>kernel_initializer</code>와 <code>bias_initializer</code>: 층의 가중치(weight)(커널(kernel)과 절편(bias))를 초기화하는 방법입니다. 내장 함수나 호출 가능한 객체를 지정합니다. 기본값은 <code>\"glorot_uniform\"</code> 초기화입니다.</li>\n",
    "<li><code>kernel_regularizer</code>와 <code>bias_regularizer</code>: L1 또는 L2 규제(regularization)와 같이 층의 가중치(커널과 절편)에 적용할 규제 방법을 지정합니다. 기본값은 규제를 적용하지 않는 것입니다.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.layers.core.Dense at 0x1cc8af1b0f0>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# 시그모이드 활성화 층을 만듭니다:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "\n",
    "# 커널 행렬에 L1 규제가 적용된 선형 활성화 층. 하이퍼파라미터 0.01은 규제의 양을 조절합니다:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# 절편 벡터에 L2 규제가 적용된 선형 활성화 층. 하이퍼파라미터 0.01은 규제의 양을 조절합니다:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# 커널을 랜덤한 직교 행렬로 초기화한 선형 활성화 층:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# 절편 벡터를 상수 2.0으로 설정한 선형 활성화 층:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n"
    }
   ],
   "source": [
    "# 훈련과 평가\n",
    "# 훈련 준비 \n",
    "# 모델을 구성한 후 compile 메서드를 호출하여 학습 과정을 설정합니다:\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "# 64개의 유닛을 가진 완전 연결 층을 모델에 추가합니다:\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "# 또 하나를 추가합니다:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# 10개의 출력 유닛을 가진 소프트맥스 층을 추가합니다:\n",
    "layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "# 평균 제곱 오차로 회귀 모델을 설정합니다.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='mse',       # 평균 제곱 오차\n",
    "              metrics=['mae'])  # 평균 절댓값 오차\n",
    "'''\n",
    "\n",
    "'''\n",
    "tf.keras.Model.compile에는 세 개의 중요한 매개변수가 있습니다:\n",
    "    - optimizer: 훈련 과정을 설정합니다.\n",
    "        tf.keras.optimizers.Adam이나 tf.keras.optimizers.SGD와 같은 tf.keras.optimizers \n",
    "        아래의 옵티마이저 객체를 전달합니다.\n",
    "        기본 매개변수를 사용할 경우 'adam'이나 'sgd'와 같이 문자열로 지정할 수도 있습니다.\n",
    "    - loss: 최적화 과정에서 최소화될 손실 함수(loss function)를 설정합니다.\n",
    "        평균 제곱 오차(mse)와 categorical_crossentropy, binary_crossentropy 등이 자주 사용됩니다.\n",
    "        손실 함수의 이름을 지정하거나 tf.keras.losses 모듈 아래의 호출 가능한 객체를 전달할 수 있습니다.\n",
    "    - metrics: 훈련을 모니터링하기 위해 사용됩니다. 이름이나 tf.keras.metrics 모듈 아래의 호출 가능한 객체입니다.\n",
    "        추가적으로 모델의 훈련과 평가를 즉시 실행하려면 run_eagerly=True 매개변수를 전달할 수 있습니다.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data:  [0.8811703  0.3258606  0.71815021 0.02397227 0.41296565 0.00752314\n 0.65575067 0.57201955 0.74498851 0.31326722 0.15364743 0.66458484\n 0.26155501 0.63207578 0.42439221 0.377938   0.3246615  0.1445364\n 0.7459114  0.53573305 0.48280354 0.24710819 0.41221608 0.53597948\n 0.49420844 0.69731648 0.24629362 0.9570717  0.68055922 0.77436399\n 0.3722159  0.32227691]\nlabes:  [0.12134507 0.72233914 0.13004131 0.71147676 0.61164363 0.22885252\n 0.23133298 0.99905552 0.14801009 0.62676988]\nWARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\nTrain on 30 steps\nEpoch 1/10\n30/30 [==============================] - 0s 4ms/step - loss: 689.5386 - acc: 0.1281\nEpoch 2/10\n 1/30 [>.............................] - ETA: 0s - loss: 1005.9798 - acc: 0.0625WARNING:tensorflow:Your dataset ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 300 batches). You may need to use the repeat() function when building your dataset.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1cc9281fe80>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "'''\n",
    "데이터셋이 작은 경우 NumPy 배열을 메모리에 적재하여 모델을 훈련하고 평가합니다.\n",
    "모델은 fit 메서드를 통해서 훈련 데이터를 학습합니다:\n",
    "'''\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "# Dataset 객체를 만듭니다:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "print( \"data: \", data[0] )\n",
    "print( \"labes: \", labels[0] )\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\nTrain on 32 steps, validate on 4 steps\nEpoch 1/10\n32/32 [==============================] - 0s 4ms/step - loss: 613.6932 - acc: 0.0920 - val_loss: 843.2909 - val_acc: 0.0900\nEpoch 2/10\n32/32 [==============================] - 0s 2ms/step - loss: 692.4323 - acc: 0.1050 - val_loss: 555.1105 - val_acc: 0.0800\nEpoch 3/10\n32/32 [==============================] - 0s 2ms/step - loss: 706.4476 - acc: 0.1020 - val_loss: 721.0131 - val_acc: 0.0600\nEpoch 4/10\n32/32 [==============================] - 0s 2ms/step - loss: 774.0157 - acc: 0.1140 - val_loss: 788.9544 - val_acc: 0.0600\nEpoch 5/10\n32/32 [==============================] - 0s 2ms/step - loss: 647.5620 - acc: 0.1090 - val_loss: 582.8086 - val_acc: 0.1300\nEpoch 6/10\n32/32 [==============================] - 0s 2ms/step - loss: 779.6659 - acc: 0.1010 - val_loss: 712.6300 - val_acc: 0.0600\nEpoch 7/10\n32/32 [==============================] - 0s 2ms/step - loss: 852.0083 - acc: 0.1070 - val_loss: 776.1504 - val_acc: 0.1300\nEpoch 8/10\n32/32 [==============================] - 0s 2ms/step - loss: 715.7784 - acc: 0.0930 - val_loss: 609.4197 - val_acc: 0.0900\nEpoch 9/10\n32/32 [==============================] - 0s 2ms/step - loss: 653.3552 - acc: 0.0930 - val_loss: 663.4235 - val_acc: 0.0600\nEpoch 10/10\n32/32 [==============================] - 0s 2ms/step - loss: 893.4767 - acc: 0.0860 - val_loss: 948.2465 - val_acc: 0.1500\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1cc92adca58>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# 다음이 validation_data를 사용하는 예입니다.\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "\n",
    "\n",
    "#model.fit(data, labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))\n",
    "model.fit(dataset, epochs=10, validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "평가와 예측\n30/30 [==============================] - 0s 2ms/step - loss: 978.5468 - acc: 0.0812\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[978.5467915852864, 0.08125]"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# 평가와 예측\n",
    "print( \"평가와 예측\")\n",
    "\n",
    "model.evaluate(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "주어진 데이터로 추론 모드에서 마지막 층의 출력을 예측하여 넘파이 배열로 반환합니다:\n(1000, 10)\n[[0.0000000e+00 0.0000000e+00 7.8045929e-26 ... 2.7678293e-36\n  0.0000000e+00 1.0000000e+00]\n [0.0000000e+00 0.0000000e+00 1.7816729e-30 ... 0.0000000e+00\n  0.0000000e+00 1.0000000e+00]\n [0.0000000e+00 0.0000000e+00 1.0594215e-32 ... 0.0000000e+00\n  0.0000000e+00 1.0000000e+00]\n ...\n [0.0000000e+00 0.0000000e+00 4.5359845e-24 ... 7.2094533e-34\n  0.0000000e+00 1.0000000e+00]\n [0.0000000e+00 0.0000000e+00 1.8537533e-26 ... 2.7405221e-37\n  0.0000000e+00 1.0000000e+00]\n [0.0000000e+00 0.0000000e+00 2.4279378e-24 ... 4.3727545e-34\n  0.0000000e+00 1.0000000e+00]]\n"
    }
   ],
   "source": [
    "#주어진 데이터로 추론 모드에서 마지막 층의 출력을 예측하여 넘파이 배열로 반환합니다:\n",
    "print( \"주어진 데이터로 추론 모드에서 마지막 층의 출력을 예측하여 넘파이 배열로 반환합니다:\" )\n",
    "\n",
    "result = model.predict(data, batch_size=32)\n",
    "print( result.shape )\n",
    "print( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36864bit49dd4257f41c41b49bea59eae1aba9be",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}